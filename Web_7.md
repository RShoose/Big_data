## **–í–µ–±–∏–Ω–∞—Ä 7: –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã MapReduce –≤ —Ä–∏—Ç–µ–π–ª-–∞–Ω–∞–ª–∏—Ç–∏–∫–µ**

### **–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å** 

---

## **1. –í—Ç–æ—Ä–∏—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (Secondary Sort) –≤ —Ä–∏—Ç–µ–π–ª–µ** 

### **–ü—Ä–æ–±–ª–µ–º–∞: –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**
```python
# –ë–µ–∑ –≤—Ç–æ—Ä–∏—á–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ - –¥–∞–Ω–Ω—ã–µ –≤—Ä–∞–∑–±—Ä–æ—Å
("2023-01", "Books")    ‚Üí 4500
("2023-02", "Electronics") ‚Üí 12000  
("2023-01", "Electronics") ‚Üí 15000
("2023-02", "Books")    ‚Üí 5200
```

### **–†–µ—à–µ–Ω–∏–µ: –°–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π**
```python
# –° –≤—Ç–æ—Ä–∏—á–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π - —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
("2023-01", "Books")       ‚Üí 4500
("2023-01", "Clothing")    ‚Üí 8900
("2023-01", "Electronics") ‚Üí 15000
("2023-02", "Books")       ‚Üí 5200
("2023-02", "Clothing")    ‚Üí 10200
("2023-02", "Electronics") ‚Üí 12000
```

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Secondary Sort**
```
üìä –î–∞–Ω–Ω—ã–µ ‚Üí üó∫Ô∏è Mapper ‚Üí üîÑ Partitioner ‚Üí üìÇ Group Comparator ‚Üí ‚ôªÔ∏è Reducer
    ‚Üì           ‚Üì              ‚Üì                 ‚Üì                 ‚Üì
   Raw        (K, V)      –ü–æ –≥–æ–¥—É-–º–µ—Å—è—Ü—É    –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏      –ê–≥—Ä–µ–≥–∞—Ü–∏—è
```

### **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º**
```
 –í—ã—Ä—É—á–∫–∞ (—Ç—ã—Å.$)
    ‚îÇ
20  ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
    ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Electronics
15  ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
    ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Clothing  
10  ‚îÇ    ‚ñà‚ñà‚ñà‚ñà            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
    ‚îÇ    ‚ñà‚ñà‚ñà‚ñà            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Books
5   ‚îÇ    ‚ñà‚ñà              ‚ñà‚ñà        ‚ñà‚ñà
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
       –Ø–Ω–≤    –§–µ–≤    –ú–∞—Ä    –ê–ø—Ä    –ú–∞–π
```

---

## **2. –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞** 

### **–ü—Ä–æ–±–ª–µ–º–∞: –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã –¥–∞–Ω–Ω—ã—Ö**
–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Ç—Ä–µ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤:
1. üó∫Ô∏è –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–æ–ª—É
2. üó∫Ô∏è –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º  
3. üó∫Ô∏è –ê–Ω–∞–ª–∏–∑ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–º –≥—Ä—É–ø–ø–∞–º
4. üó∫Ô∏è –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º

### **–†–µ—à–µ–Ω–∏–µ: –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ —Å —Å–æ—Å—Ç–∞–≤–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏**
```python
# –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –≤ –æ–¥–Ω–æ–º Job
("Gender-Male", "Revenue")        ‚Üí 150000
("Gender-Female", "Revenue")      ‚Üí 120000
("Category-Electronics", "Revenue") ‚Üí 90000
("Age-25-34", "Revenue")          ‚Üí 80000
("Gender-Category-Male-Electronics", "Revenue") ‚Üí 45000
```

### **–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è**
```
         Electronics  Clothing  Books  Home
Male       45,000     35,000   15,000 25,000
Female     30,000     55,000   20,000 15,000

        18-24      25-34      35-44      45+
Male   20,000     45,000     35,000   20,000  
Female 25,000     40,000     35,000   20,000
```

### **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –ì–µ–Ω–¥–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º**
```
 –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫ –ø–æ –ø–æ–ª—É –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
100% ‚îÇ
     ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
     ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
 75% ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
     ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë Female
 50% ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
     ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë Male
 25% ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
     ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
  0% ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      Electronics   Clothing   Books    Home
```

---

## **3. Multiple Outputs - –µ–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –¥–ª—è –≤—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏** 

### **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞**
```
üìà –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    ‚Üì
üîÑ –ï–¥–∏–Ω—ã–π Mapper
    ‚Üì  
üìä Multiple Outputs
    ‚îú‚îÄ‚îÄ üóìÔ∏è  –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –º–µ—Å—è—Ü–∞–º
    ‚îú‚îÄ‚îÄ üë•  –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–æ–ª—É
    ‚îú‚îÄ‚îÄ üì¶  –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    ‚îú‚îÄ‚îÄ üéØ  –°–æ—Å—Ç–∞–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    ‚îî‚îÄ‚îÄ üìà  –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
```

### **–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Ç–µ–π–ª-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏**
```python
# –í –æ–¥–Ω–æ–º Mapper-–µ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
METRICS = {
    "–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã": ["MONTHLY", "WEEKLY", "DAILY"],
    "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ": ["CATEGORY", "SUBCATEGORY", "BRAND"], 
    "–ö–ª–∏–µ–Ω—Ç—Å–∫–∏–µ": ["GENDER", "AGE_GROUP", "REGION"],
    "–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ": ["AVG_RECEIPT", "BASKET_SIZE", "FREQUENCY"],
    "–°–æ—Å—Ç–∞–≤–Ω—ã–µ": ["GENDER_CATEGORY", "AGE_REGION", "SEASONALITY"]
}
```

### **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –¥–∞—à–±–æ—Ä–¥-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞**
```
RETAIL ANALYTICS DASHBOARD
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ–í–†–ï–ú–ï–ù–ù–´–ï –†–Ø–î–´   ‚îÇ    –ö–õ–ò–ï–ù–¢–´      ‚îÇ   –ü–†–û–î–£–ö–¢–´      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  150K ‚ÜóÔ∏é 15%     ‚îÇ   Male: 55%     ‚îÇ  Electronics    ‚îÇ
‚îÇ  125K ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚îÇ   Female: 45%   ‚îÇ  Clothing ‚ñà‚ñà‚ñà‚ñà  ‚îÇ
‚îÇ  100K ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚îÇ                 ‚îÇ  Books    ‚ñà‚ñà    ‚îÇ
‚îÇ   75K ‚ñà‚ñà‚ñà‚ñà      ‚îÇ   25-34: 40%    ‚îÇ  Home     ‚ñà‚ñà    ‚îÇ
‚îÇ   50K ‚ñà‚ñà        ‚îÇ   35-44: 30%    ‚îÇ                 ‚îÇ
‚îÇ   25K ‚ñà         ‚îÇ   18-24: 20%    ‚îÇ  Avg Receipt:   ‚îÇ
‚îÇ    0K           ‚îÇ   45+: 10%      ‚îÇ    $85.20 ‚ÜóÔ∏é     ‚îÇ
‚îÇ   J F M A M J   ‚îÇ                 ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## **4. –ë–∏–∑–Ω–µ—Å-–∫–µ–π—Å—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è** (10 –º–∏–Ω)

### **–ö–µ–π—Å 1: –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂**
```
üéÑ –°–ï–ó–û–ù–ù–û–°–¢–¨ –ü–†–û–î–ê–ñ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú
    ‚îÇ
200%‚îÇ              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
    ‚îÇ              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Electronics 
150%‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
    ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Clothing
100%‚îÇ    ‚ñà‚ñà  ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà
    ‚îÇ    ‚ñà‚ñà  ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà  ‚ñà‚ñà  ‚ñà‚ñà Books
 50%‚îÇ  ‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà
    ‚îÇ  ‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà    ‚ñà‚ñà
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
       Q1   Q2   Q3   Q4   Holidays
```

### **–ö–µ–π—Å 2: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π**
```
–°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø –ü–û–ö–£–ü–ê–¢–ï–õ–ï–ô
High-Value    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 18%  | $500+ avg
Medium-Value  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 25%  | $200-500  
Low-Value     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 35% | $50-200
Occasional    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 22%  | <$50

–í–û–ó–†–ê–°–¢–ù–´–ï –°–ï–ì–ú–ï–ù–¢–´
18-24: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 20%   | Tech-savvy, impulse buys
25-34: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 35%   | Family needs, value
35-44: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 28%   | Quality focused  
45+:   ‚ñà‚ñà‚ñà‚ñà‚ñà 17%   | Brand loyal, traditional
```

### **–ö–µ–π—Å 3: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞**
```
ROI –ü–û –ö–ê–ù–ê–õ–ê–ú –ü–†–û–î–ê–ñ
Online   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 45%  | $2.10 ROI
Mobile   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 32%  | $1.80 ROI
Store    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 23%  | $1.20 ROI

 –¶–ï–õ–ï–í–´–ï –ê–£–î–ò–¢–û–†–ò–ò
Electronics: Male 25-34 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Clothing: Female 18-29 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  
Books: Mixed 25-45 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Home: Female 35-55 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
```

---

## **5. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** (5 –º–∏–Ω)

### **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**
```
‚ö° –ü–ê–¢–¢–ï–†–ù–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò

–ö–æ–º–±–∞–π–Ω–µ—Ä—ã:    –õ–æ–∫–∞–ª—å–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –Ω–∞ mapper-—É–∑–ª–∞—Ö
–ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏  
In-Mapper Combiner: –£–º–µ–Ω—å—à–µ–Ω–∏–µ network I/O
Multiple Outputs: –ò–∑–±–µ–∂–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤

–ú–ï–¢–†–ò–ö–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò

Data Locality:    95%  ‚úÖ
Network Transfer: 2.1GB  ‚úÖ  
Execution Time:   3.2min ‚úÖ
Resource Usage:   78%   ‚úÖ
```
# **–ü—Ä–∞–∫—Ç–∏–∫–∞**
---

## **üéØ –°–ö–†–ò–ü–¢–´ –ò –ò–• –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –ë–ê–ó–ê**

### **1. `secondary_sort.py` - –í–¢–û–†–ò–ß–ù–ê–Ø –°–û–†–¢–ò–†–û–í–ö–ê**
```python
"""
 –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –í—Ç–æ—Ä–∏—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (Secondary Sort)

–ü–†–û–ë–õ–ï–ú–ê: –î–∞–Ω–Ω—ã–µ –ø—Ä–∏—Ö–æ–¥—è—Ç –≤—Ä–∞–∑–±—Ä–æ—Å:
("2023-01", "Books") ‚Üí 4500
("2023-02", "Electronics") ‚Üí 12000  
("2023-01", "Electronics") ‚Üí 15000

–†–ï–®–ï–ù–ò–ï: –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º –ò –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:
("2023-01", "Books") ‚Üí 4500
("2023-01", "Electronics") ‚Üí 15000
("2023-02", "Books") ‚Üí 5200

–¢–ï–•–ù–ò–ö–ê:
- –°–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á: (year_month, category)
- –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π reducer
- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤—ã—Ä—É—á–∫–∏ –≤–Ω—É—Ç—Ä–∏ –º–µ—Å—è—Ü–∞
"""
```
**–°–æ–∑–¥–∞–µ–º `secondary_sort.py`:**
```python
#!/usr/bin/env python3
from mrjob.job import MRJob
from mrjob.step import MRStep
from datetime import datetime

class RealSecondarySort(MRJob):
    
    def mapper(self, _, line):
        if 'Transaction ID' in line:
            return
            
        parts = line.split(',')
        if len(parts) >= 9:
            try:
                date_str = parts[1].strip()
                category = parts[5].strip()
                total_amount = float(parts[8])
                
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                year_month = date_obj.strftime('%Y-%m')
                
                # –ö–ª—é—á: (–≥–æ–¥-–º–µ—Å—è—Ü, –∫–∞—Ç–µ–≥–æ—Ä–∏—è) - —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –æ–±–æ–∏–º –ø–æ–ª—è–º
                yield (year_month, category), total_amount
                
            except (ValueError, IndexError):
                pass

    def reducer(self, key, values):
        year_month, category = key
        total_sales = sum(values)
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≥–æ–¥—É-–º–µ—Å—è—Ü—É, –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã
        yield year_month, (category, total_sales)

    def final_reducer(self, year_month, category_sales):
        # –í–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏—Ö–æ–¥—è—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏
        sales_by_category = []
        for category, sales in category_sales:
            sales_by_category.append((category, sales))
        
        # –í—ã–≤–æ–¥–∏–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for category, sales in sorted(sales_by_category, key=lambda x: x[1], reverse=True):
            yield f"{year_month}_{category}", sales

    def steps(self):
        return [
            MRStep(mapper=self.mapper,
                   reducer=self.reducer),
            MRStep(reducer=self.final_reducer)
        ]

if __name__ == '__main__':
    RealSecondarySort.run()
```
–ö–æ–ø–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
`docker cp secondary_sort.py namenode:/scripts/`

–ó–∞–ø—É—Å–∫–∞–µ–º –í–ù–£–¢–†–ò –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

```
docker-compose exec namenode bash
export PATH="/tmp/python/bin:$PATH"
cd /scripts
```

–ó–∞–ø—É—Å–∫–∞–µ–º –í–¢–û–†–ò–ß–ù–£–Æ –°–û–†–¢–ò–†–û–í–ö–£
```
python3 secondary_sort.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/secondary_sort
``` 
<details>
  <summary>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</summary>
    
### **1. `visualize_secondary_sort.py` - –í–¢–û–†–ò–ß–ù–ê–Ø –°–û–†–¢–ò–†–û–í–ö–ê**
```python
#!/usr/bin/env python3
import subprocess
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd
from collections import defaultdict

def get_all_secondary_sort_data():
    cmd = "hdfs dfs -cat /user/root/output/secondary_sort/part-*"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
    data = []
    for line in result.stdout.strip().split('\n'):
        if '\t' in line and 'INFO' not in line:
            key, value = line.split('\t')
            try:
                key_clean = key.strip('"')
                if '_' in key_clean:
                    year_month, category = key_clean.split('_', 1)
                    sales = float(value)
                    data.append({
                        'year_month': year_month,
                        'category': category,
                        'sales': sales
                    })
            except:
                continue
    return data

def create_combined_analysis():
    print("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤...")
    data = get_all_secondary_sort_data()
    
    if not data:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    df = pd.DataFrame(data)
    
    # === –¢–ï–ö–°–¢–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
    print("\n" + "="*80)
    print("–¢–ï–ö–°–¢–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–¢–û–†–ò–ß–ù–û–ô –°–û–†–¢–ò–†–û–í–ö–ò")
    print("="*80)
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_revenue = df['sales'].sum()
    total_months = df['year_month'].nunique()
    categories_count = df['category'].nunique()
    
    print(f"–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(data)}")
    print(f"‚Ä¢ –ú–µ—Å—è—Ü–µ–≤: {total_months}") 
    print(f"‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {categories_count}")
    print(f"‚Ä¢ –í—ã—Ä—É—á–∫–∞: ${total_revenue:,.2f}")
    print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_totals = df.groupby('category')['sales'].sum().sort_values(ascending=False)
    
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    print("-" * 50)
    for i, (category, revenue) in enumerate(category_totals.items(), 1):
        share = (revenue / total_revenue) * 100
        print(f"{i}. {category}: ${revenue:,.2f} ({share:.1f}%)")
    print()
    
    # –õ–∏–¥–µ—Ä—ã –ø–æ –º–µ—Å—è—Ü–∞–º
    monthly_leaders = df.loc[df.groupby('year_month')['sales'].idxmax()]
    
    print("–õ–ò–î–ï–†–´ –ü–û –ú–ï–°–Ø–¶–ê–ú:")
    print("-" * 50)
    for _, row in monthly_leaders.sort_values('year_month').iterrows():
        print(f"{row['year_month']}: {row['category']} (${row['sales']:,.2f})")
    
    # === –°–û–ó–î–ê–ï–ú –ì–†–ê–§–ò–ö ===
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞...")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('–ê–ù–ê–õ–ò–ó –í–¢–û–†–ò–ß–ù–û–ô –°–û–†–¢–ò–†–û–í–ö–ò: –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º', 
                fontsize=16, fontweight='bold')
    
    # 1. Heatmap
    pivot_sales = df.pivot_table(index='year_month', columns='category', 
                                values='sales', aggfunc='sum').fillna(0)
    pivot_sales = pivot_sales.sort_index()
    
    im = ax1.imshow(pivot_sales.values, cmap='YlOrRd', aspect='auto')
    ax1.set_xticks(range(len(pivot_sales.columns)))
    ax1.set_yticks(range(len(pivot_sales.index)))
    ax1.set_xticklabels(pivot_sales.columns, rotation=45, ha='right')
    ax1.set_yticklabels(pivot_sales.index)
    ax1.set_title('–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –ø—Ä–æ–¥–∞–∂\n(–≤—Ç–æ—Ä–∏—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º)')
    
    for i in range(len(pivot_sales.index)):
        for j in range(len(pivot_sales.columns)):
            if pivot_sales.iloc[i, j] > 0:
                ax1.text(j, i, f'{pivot_sales.iloc[i, j]/1000:.0f}K', 
                        ha="center", va="center", color="black", fontsize=8)
    
    plt.colorbar(im, ax=ax1, label='–í—ã—Ä—É—á–∫–∞ ($)')
    
    # 2. –î–æ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    ax2.pie(category_totals.values, labels=category_totals.index, autopct='%1.1f%%',
           startangle=90, colors=['#ff6b6b', '#4ecdc4', '#45b7d1'])
    ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º')
    
    # 3. –î–∏–Ω–∞–º–∏–∫–∞ —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    top_categories = category_totals.head(2).index
    for category in top_categories:
        category_data = df[df['category'] == category].sort_values('year_month')
        ax3.plot(category_data['year_month'], category_data['sales'], 
                marker='o', linewidth=2, label=category)
    
    ax3.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —Ç–æ–ø-2 –∫–∞—Ç–µ–≥–æ—Ä–∏–π')
    ax3.set_ylabel('–í—ã—Ä—É—á–∫–∞ ($)')
    ax3.legend()
    ax3.tick_params(axis='x', rotation=45)
    ax3.grid(True, alpha=0.3)
    
    # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ª–∏–¥–µ—Ä–æ–≤
    leader_counts = monthly_leaders['category'].value_counts()
    bars = ax4.bar(leader_counts.index, leader_counts.values, 
                  color=['#ff9999', '#66b3ff', '#99ff99'])
    ax4.set_title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—è—Ü–µ–≤ –≤ –ª–∏–¥–µ—Ä–∞—Ö\n–ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º')
    ax4.set_ylabel('–ú–µ—Å—è—Ü–µ–≤')
    
    for bar, count in zip(bars, leader_counts.values):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                f'{count}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('/scripts/combined_analysis.png', dpi=100, bbox_inches='tight')
    plt.close()
    
    print(f"\n–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: combined_analysis.png")
    print(f"–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: ${total_revenue:,.2f}")
    print(f"–¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_totals.index[0]} (${category_totals.iloc[0]:,.2f})")

if __name__ == '__main__':
    create_combined_analysis()
```
```bash
# 1. –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
docker-compose exec namenode hdfs dfs -rm -r /user/root/output/secondary_sort

# 2. –ö–æ–ø–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker cp secondary_sort.py namenode:/scripts/
docker cp visualize_secondary_sort.py namenode:/scripts/

# 3. –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
docker-compose exec namenode bash
cd /scripts

python3 secondary_sort.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/secondary_sort

# 4. –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
python3 visualize_secondary_sort.py

# 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
hdfs dfs -cat /user/root/output/secondary_sort/part-00000 | head -10

# 6. –ö–æ–ø–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ —Ö–æ—Å—Ç
docker cp namenode:/scripts/combined_analysis.png ./

# 7. –°–º–æ—Ç—Ä–∏–º –≥—Ä–∞—Ñ–∏–∫
feh combined_analysis.png
```
</details>

### **2. `composite_keys.py` - –°–û–°–¢–ê–í–ù–´–ï –ö–õ–Æ–ß–ò**
```python
"""
–¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

–ü–†–û–ë–õ–ï–ú–ê: –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Ç—Ä–µ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤:
1. –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–æ–ª—É ‚Üí 1 Job
2. –ê–Ω–∞–ª–∏–∑ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É ‚Üí 2 Job  
3. –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ‚Üí 3 Job

–†–ï–®–ï–ù–ò–ï: –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ —Å —Å–æ—Å—Ç–∞–≤–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏:
"CROSS_GENDER_CATEGORY_Male_Electronics" ‚Üí 45000
"CROSS_AGE_CATEGORY_25-34_Books" ‚Üí 15000
"TRIPLE_Female_25-34_Electronics" ‚Üí 12000

–¢–ï–•–ù–ò–ö–ê:
- –ö–ª—é—á–∏ –∫–∞–∫ –∏–∑–º–µ—Ä–µ–Ω–∏—è: DEMO_GENDER_, PRODUCT_, CROSS_
- –ö—Ä–æ—Å—Å-—Å–µ–∫—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –æ–¥–Ω–æ–º mapper
- –ò–∑–±–µ–∂–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ –¥–∞–Ω–Ω—ã–º
"""
```
**–°–æ–∑–¥–∞–µ–º `composite_keys.py`:**
```python
#!/usr/bin/env python3
from mrjob.job import MRJob
from datetime import datetime

class CompositeKeysAnalysis(MRJob):

    def mapper(self, _, line):
        if 'Transaction ID' in line:
            return
            
        parts = line.split(',')
        if len(parts) >= 9:
            try:
                date_str = parts[1].strip()
                gender = parts[3].strip()
                age = int(parts[4])
                category = parts[5].strip()
                total_amount = float(parts[8])
                
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                year_month = date_obj.strftime('%Y-%m')
                age_group = self.get_age_group(age)
                season = self.get_season(date_obj.month)
                
                # –°–û–°–¢–ê–í–ù–´–ï –ö–õ–Æ–ß–ò - –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã
                yield f"TIME_{year_month}", total_amount
                yield f"TIME_SEASON_{season}", total_amount
                
                # –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Ä–µ–∑—ã  
                yield f"DEMO_GENDER_{gender}", total_amount
                yield f"DEMO_AGE_{age_group}", total_amount
                
                # –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ —Å—Ä–µ–∑—ã
                yield f"PRODUCT_{category}", total_amount
                
                # –ö–†–û–°–°-–°–ï–ö–¶–ò–û–ù–ù–´–ï –ê–ù–ê–õ–ò–ó–´ (—Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏)
                yield f"CROSS_GENDER_CATEGORY_{gender}_{category}", total_amount
                yield f"CROSS_AGE_CATEGORY_{age_group}_{category}", total_amount
                yield f"CROSS_SEASON_CATEGORY_{season}_{category}", total_amount
                yield f"CROSS_GENDER_AGE_{gender}_{age_group}", total_amount
                
                # –¢—Ä–æ–π–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
                yield f"TRIPLE_{gender}_{age_group}_{category}", total_amount
                
            except (ValueError, IndexError) as e:
                self.increment_counter('errors', 'parsing_error', 1)

    def get_age_group(self, age):
        if age <= 24: return "18-24"
        elif age <= 34: return "25-34" 
        elif age <= 44: return "35-44"
        elif age <= 54: return "45-54"
        else: return "55+"

    def get_season(self, month):
        if month in [12, 1, 2]: return "WINTER"
        elif month in [3, 4, 5]: return "SPRING"
        elif month in [6, 7, 8]: return "SUMMER"
        else: return "AUTUMN"

    def reducer(self, key, values):
        total = sum(values)
        count = sum(1 for _ in values)
        
        if key.startswith("TRIPLE"):
            yield key, f"${total:,.2f} ({count} –ø–æ–∫—É–ø–æ–∫)"
        else:
            yield key, f"${total:,.2f}"

if __name__ == '__main__':
    CompositeKeysAnalysis.run()
```
<details>
  <summary>–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è</summary>
    
### **`visualize_composite_keys.py`
```python
#!/usr/bin/env python3
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import subprocess
import numpy as np
import pandas as pd

def main():
    print("–ú–ù–û–ì–û–ú–ï–†–ù–´–ô –ê–ù–ê–õ–ò–ó: –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏")
    
    # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ
    cmd = "hdfs dfs -cat /user/root/output/composite_keys/part-*"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ü–†–ê–í–ò–õ–¨–ù–´–ú –ø–∞—Ä—Å–∏–Ω–≥–æ–º
    gender_age_data = []
    age_category_data = []
    gender_category_data = []
    season_category_data = []
    
    for line in result.stdout.strip().split('\n'):
        if '\t' in line and 'INFO' not in line:
            key, value = line.split('\t')
            key = key.strip('"')
            value = value.strip('"')
            
            try:
                # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å $
                if value.startswith('$'):
                    amount = float(value.replace('$', '').replace(',', ''))
                    
                    # CROSS_GENDER_AGE - –ø–æ–ª √ó –≤–æ–∑—Ä–∞—Å—Ç
                    if key.startswith('CROSS_GENDER_AGE_'):
                        parts = key.split('_')
                        if len(parts) >= 5:
                            gender = parts[3]  # Female
                            age_group = parts[4]  # 18-24
                            gender_age_data.append({
                                'gender': gender,
                                'age_group': age_group,
                                'amount': amount
                            })
                    
                    # CROSS_AGE_CATEGORY - –≤–æ–∑—Ä–∞—Å—Ç √ó –∫–∞—Ç–µ–≥–æ—Ä–∏—è
                    elif key.startswith('CROSS_AGE_CATEGORY_'):
                        parts = key.split('_')
                        if len(parts) >= 5:
                            age_group = parts[3]  # 18-24
                            category = parts[4]   # Beauty
                            age_category_data.append({
                                'age_group': age_group,
                                'category': category,
                                'amount': amount
                            })
                    
                    # CROSS_GENDER_CATEGORY - –ø–æ–ª √ó –∫–∞—Ç–µ–≥–æ—Ä–∏—è
                    elif key.startswith('CROSS_GENDER_CATEGORY_'):
                        parts = key.split('_')
                        if len(parts) >= 5:
                            gender = parts[3]  # Female
                            category = parts[4]  # Beauty
                            gender_category_data.append({
                                'gender': gender,
                                'category': category,
                                'amount': amount
                            })
                    
                    # CROSS_SEASON_CATEGORY - —Å–µ–∑–æ–Ω √ó –∫–∞—Ç–µ–≥–æ—Ä–∏—è
                    elif key.startswith('CROSS_SEASON_CATEGORY_'):
                        parts = key.split('_')
                        if len(parts) >= 5:
                            season = parts[3]  # AUTUMN
                            category = parts[4]  # Beauty
                            season_category_data.append({
                                'season': season,
                                'category': category,
                                'amount': amount
                            })
                        
            except:
                continue
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('–ú–ù–û–ì–û–ú–ï–†–ù–´–ô –ê–ù–ê–õ–ò–ó: –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –¥–µ–º–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è', 
                fontsize=16, fontweight='bold')
    
    # 1. Heatmap: –ü–æ–ª √ó –í–æ–∑—Ä–∞—Å—Ç
    if gender_age_data:
        df = pd.DataFrame(gender_age_data)
        pivot = df.pivot_table(index='gender', columns='age_group', values='amount', aggfunc='sum').fillna(0)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã
        age_order = ['18-24', '25-34', '35-44', '45-54', '55+']
        pivot = pivot[age_order]
        
        im1 = ax1.imshow(pivot.values, cmap='YlOrRd', aspect='auto')
        ax1.set_xticks(range(len(age_order)))
        ax1.set_yticks(range(len(pivot.index)))
        ax1.set_xticklabels(age_order)
        ax1.set_yticklabels(pivot.index)
        ax1.set_title('–ü–û–õ √ó –í–û–ó–†–ê–°–¢\n–í—ã—Ä—É—á–∫–∞ –ø–æ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º –≥—Ä—É–ø–ø–∞–º')
        ax1.set_xlabel('–í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã')
        ax1.set_ylabel('–ü–æ–ª')
        
        for i in range(len(pivot.index)):
            for j in range(len(age_order)):
                value = pivot.iloc[i, j]
                if value > 0:
                    ax1.text(j, i, f'${value/1000:.0f}K', 
                            ha="center", va="center", color="black", fontsize=10,
                            fontweight='bold')
        
        plt.colorbar(im1, ax=ax1, label='–í—ã—Ä—É—á–∫–∞ ($)')
    
    # 2. Heatmap: –í–æ–∑—Ä–∞—Å—Ç √ó –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    if age_category_data:
        df = pd.DataFrame(age_category_data)
        pivot = df.pivot_table(index='age_group', columns='category', values='amount', aggfunc='sum').fillna(0)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã
        age_order = ['18-24', '25-34', '35-44', '45-54', '55+']
        pivot = pivot.reindex(age_order)
        
        im2 = ax2.imshow(pivot.values, cmap='Blues', aspect='auto')
        ax2.set_xticks(range(len(pivot.columns)))
        ax2.set_yticks(range(len(age_order)))
        ax2.set_xticklabels(pivot.columns, rotation=45, ha='right')
        ax2.set_yticklabels(age_order)
        ax2.set_title('–í–û–ó–†–ê–°–¢ √ó –ö–ê–¢–ï–ì–û–†–ò–Ø\n–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–º')
        ax2.set_xlabel('–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤')
        ax2.set_ylabel('–í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –≥—Ä—É–ø–ø—ã')
        
        for i in range(len(age_order)):
            for j in range(len(pivot.columns)):
                value = pivot.iloc[i, j]
                if value > 0:
                    ax2.text(j, i, f'${value/1000:.0f}K', 
                            ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im2, ax=ax2, label='–í—ã—Ä—É—á–∫–∞ ($)')
    
    # 3. Grouped bar: –ü–æ–ª √ó –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    if gender_category_data:
        df = pd.DataFrame(gender_category_data)
        pivot = df.pivot_table(index='gender', columns='category', values='amount', aggfunc='sum').fillna(0)
        
        categories = pivot.columns
        x = np.arange(len(pivot.index))
        width = 0.25
        
        for i, category in enumerate(categories):
            offset = width * i
            values = pivot[category].values
            ax3.bar(x + offset, values, width, label=category,
                   color=plt.cm.Set3(i / len(categories)))
            
            for j, value in enumerate(values):
                ax3.text(j + offset, value + 1000, f'${value/1000:.0f}K',
                        ha='center', va='bottom', fontsize=8, fontweight='bold')
        
        ax3.set_xticks(x + width)
        ax3.set_xticklabels(pivot.index)
        ax3.set_title('–ü–û–õ √ó –ö–ê–¢–ï–ì–û–†–ò–Ø\n–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ –ø–æ–ª—É')
        ax3.set_ylabel('–í—ã—Ä—É—á–∫–∞ ($)')
        ax3.legend(title='–ö–∞—Ç–µ–≥–æ—Ä–∏–∏')
    
    # 4. Stacked bar: –°–µ–∑–æ–Ω √ó –ö–∞—Ç–µ–≥–æ—Ä–∏—è
    if season_category_data:
        df = pd.DataFrame(season_category_data)
        pivot = df.pivot_table(index='season', columns='category', values='amount', aggfunc='sum').fillna(0)
        
        categories = pivot.columns
        x = range(len(pivot.index))
        bottom = np.zeros(len(pivot.index))
        
        for i, category in enumerate(categories):
            values = pivot[category].values
            ax4.bar(x, values, bottom=bottom, label=category, 
                   color=plt.cm.Pastel1(i / len(categories)))
            bottom += values
        
        ax4.set_xticks(x)
        ax4.set_xticklabels(pivot.index)
        ax4.set_title('–°–ï–ó–û–ù √ó –ö–ê–¢–ï–ì–û–†–ò–Ø\n–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è')
        ax4.set_ylabel('–í—ã—Ä—É—á–∫–∞ ($)')
        ax4.legend(title='–ö–∞—Ç–µ–≥–æ—Ä–∏–∏')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Å—É–º–º—ã
        for i, season in enumerate(pivot.index):
            total = pivot.loc[season].sum()
            ax4.text(i, total + 2000, f'${total/1000:.0f}K', 
                    ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('/scripts/composite_keys_analysis.png', dpi=100, bbox_inches='tight')
    plt.close()
    
    print("–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: composite_keys_analysis.png")
    
    # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
    print(f"\n–ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:")
    
    if gender_age_data:
        df = pd.DataFrame(gender_age_data)
        max_combo = df.loc[df['amount'].idxmax()]
        print(f"‚Ä¢ –°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ: {max_combo['gender']} {max_combo['age_group']} (${max_combo['amount']:,.0f})")
    
    if age_category_data:
        df = pd.DataFrame(age_category_data)
        max_combo = df.loc[df['amount'].idxmax()]
        print(f"‚Ä¢ –°–∞–º—ã–π –ø—Ä–∏–±—ã–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç: {max_combo['age_group']} –ø–æ–∫—É–ø–∞—é—Ç {max_combo['category']} (${max_combo['amount']:,.0f})")

if __name__ == '__main__':
    main()
```
# 1. –ö–æ–ø–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker cp composite_keys.py namenode:/scripts/
docker cp visualize_composite_keys.py namenode:/scripts/

# 2. –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
docker-compose exec namenode bash
cd /scripts

python3 composite_keys.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/composite_keys

# 4. –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
python3 visualize_composite_keys.py

# 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
hdfs dfs -cat /user/root/output/composite_keys/part-00000 | head -10

# 6. –ö–æ–ø–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ —Ö–æ—Å—Ç
docker cp namenode:/scripts/composite_keys_analysis.png ./

# 7. –°–º–æ—Ç—Ä–∏–º –≥—Ä–∞—Ñ–∏–∫
feh composite_keys_analysis.png

</details>

### **3. `multiple_outputs.py` - MULTIPLE OUTPUTS**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: Multiple Outputs - –µ–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –¥–ª—è –≤—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

–ü–†–û–ë–õ–ï–ú–ê: –†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Ç—Ä–µ–±—É—é—Ç —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤—ã–≤–æ–¥–∞

–†–ï–®–ï–ù–ò–ï: –ï–¥–∏–Ω—ã–π Mapper ‚Üí Multiple Outputs:
‚îú‚îÄ‚îÄ TREND_MONTHLY_2023-01 ‚Üí $45,000
‚îú‚îÄ‚îÄ DEMO_GENDER_Male ‚Üí $150,000  
‚îú‚îÄ‚îÄ PRODUCT_Electronics_REVENUE ‚Üí $90,000
‚îú‚îÄ‚îÄ METRIC_AVG_RECEIPT ‚Üí $85.20
‚îî‚îÄ‚îÄ SEGMENT_HIGH_VALUE_Male_25-34 ‚Üí $45,000

üîß –¢–ï–•–ù–ò–ö–ê:
- –†–∞–∑–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –∫–ª—é—á–µ–π = —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ –¥–∞–Ω–Ω—ã–º
- –†–∞–∑–¥–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ reducer
"""
```

### **4. `real_price_elasticity.py` - –¶–ï–ù–û–í–ê–Ø –≠–õ–ê–°–¢–ò–ß–ù–û–°–¢–¨**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –°–ª–æ–∂–Ω—ã–µ –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏

–ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å–ø—Ä–æ—Å–∞ –æ—Ç —Ü–µ–Ω—ã

–†–ï–®–ï–ù–ò–ï: –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–æ–≤–æ–π —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏:
"ELASTICITY_Electronics_PRICE" ‚Üí {"avg": 85.50, "min": 25, "max": 299}
"ELASTICITY_Electronics_QUANTITY" ‚Üí "2.1 –µ–¥."
"SEGMENT_PRICE_Electronics_PREMIUM" ‚Üí $45,200

üîß –¢–ï–•–ù–ò–ö–ê:
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∞–≥—Ä–µ–≥–∞—Ç—ã (mean, min, max)
- –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: BUDGET/STANDARD/PREMIUM/LUXURY
- –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–æ–≤: SINGLE/SMALL/MEDIUM/BULK
- –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
"""
```

### **5. `demographic_category_analysis.py` - –ú–ù–û–ì–û–ú–ï–†–ù–ê–Ø –ì–†–£–ü–ü–ò–†–û–í–ö–ê**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É, –ø–æ–ª—É –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º

–ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–æ—Å—Ç—ã–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è

–†–ï–®–ï–ù–ò–ï: –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞:
"GENDER_CATEGORY_Male_Electronics" ‚Üí $45,000
"AGE_CATEGORY_25-34_Books" ‚Üí $15,000  
"GENDER_AGE_CATEGORY_Female_35-44_Clothing" ‚Üí $28,000

üîß –¢–ï–•–ù–ò–ö–ê:
- –î–≤–æ–π–Ω—ã–µ –∏ —Ç—Ä–æ–π–Ω—ã–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
- –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–∏
- –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –¥–µ–º–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤
"""
```

### **6. `time_pattern_analysis.py` - –í–†–ï–ú–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –¥–Ω—è–º/–º–µ—Å—è—Ü–∞–º + –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

–ü–†–û–ë–õ–ï–ú–ê: –í—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

–†–ï–®–ï–ù–ò–ï: –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑:
"WEEKDAY_Monday" ‚Üí $45,200
"WEEKEND_1" ‚Üí $120,500 (–≤—ã—Ö–æ–¥–Ω—ã–µ)
"CATEGORY_SEASON_Electronics_SUMMER" ‚Üí $89,000

üîß –¢–ï–•–ù–ò–ö–ê:
- –†–∞–∑–ª–∏—á–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã: –¥–Ω–∏, –Ω–µ–¥–µ–ª–∏, –º–µ—Å—è—Ü—ã, —Å–µ–∑–æ–Ω—ã
- –ê–Ω–∞–ª–∏–∑ –±—É–¥–Ω–∏/–≤—ã—Ö–æ–¥–Ω—ã–µ
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
"""
```

### **7. `revenue_dynamics.py` - –î–ò–ù–ê–ú–ò–ö–ê –ú–ï–¢–†–ò–ö**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –î–∏–Ω–∞–º–∏–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞ –∏ –≤—ã—Ä—É—á–∫–∏

–ü–†–û–ë–õ–ï–ú–ê: –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑ —Ç—Ä–µ–Ω–¥–æ–≤

–†–ï–®–ï–ù–ò–ï: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:
"–°–†–ï–î–ù–ò–ô_–ß–ï–ö_2023-01" ‚Üí $85.20
"–í–´–†–£–ß–ö–ê_GENDER_CATEGORY_Male_Electronics" ‚Üí $45,000
"GROWTH_BASE_2023-02" ‚Üí +15%

üîß –¢–ï–•–ù–ò–ö–ê:
- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞
- –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º
- –ö—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–æ—Å—Ç–∞
"""
```

### **8. `comprehensive_time_analysis.py` - –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó**
```python
"""
üìö –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ê–Ø –û–°–ù–û–í–ê: –ü–æ–ª–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏–π

–ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–æ—Å—Ç—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø–æ–ª–Ω—É—é –∫–∞—Ä—Ç–∏–Ω—É

–†–ï–®–ï–ù–ò–ï: –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
"FULL_PATTERN_Male_25-34_Electronics_MORNING" ‚Üí $12,500
"FULL_PATTERN_Female_35-44_Clothing_Saturday" ‚Üí $8,200

üîß –¢–ï–•–ù–ò–ö–ê:
- –ü–æ–ª–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è: –î–µ–º–æ–≥—Ä–∞—Ñ–∏—è + –ö–∞—Ç–µ–≥–æ—Ä–∏—è + –í—Ä–µ–º—è
- –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫: MORNING/AFTERNOON/EVENING/NIGHT
- –î–Ω–∏ –Ω–µ–¥–µ–ª–∏ + –≤—Ä–µ–º—è —Å—É—Ç–æ–∫
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–∫—É–ø–æ–∫
"""
```

---

## **üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –°–í–Ø–ó–ò –¢–ï–û–†–ò–ò –ò –ü–†–ê–ö–¢–ò–ö–ò**

| –°–∫—Ä–∏–ø—Ç | –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω | –ë–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å |
|--------|---------------------|-----------------|
| `secondary_sort.py` | –í—Ç–æ—Ä–∏—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ | –£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º |
| `composite_keys.py` | –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏ | –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ |
| `multiple_outputs.py` | Multiple Outputs | –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏–∑ –æ–¥–Ω–æ–≥–æ Job |
| `real_price_elasticity.py` | –°–ª–æ–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ | –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ —Å–ø—Ä–æ—Å–∞ |
| `demographic_category.py` | –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ | –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π |
| `time_pattern_analysis.py` | –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã | –°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∏ —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂ |
| `revenue_dynamics.py` | –î–∏–Ω–∞–º–∏–∫–∞ –º–µ—Ç—Ä–∏–∫ | –¢—Ä–µ–Ω–¥—ã –∏ —Ä–æ—Å—Ç –±–∏–∑–Ω–µ—Å–∞ |
| `comprehensive_time.py` | –ü–æ–ª–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è | –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è |

---



### **2. –°–û–°–¢–ê–í–ù–´–ï –ö–õ–Æ–ß–ò –î–õ–Ø –ú–ù–û–ì–û–ú–ï–†–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê**

**–°–æ–∑–¥–∞–µ–º `composite_keys.py`:**
```python
#!/usr/bin/env python3
from mrjob.job import MRJob
from datetime import datetime

class CompositeKeysAnalysis(MRJob):

    def mapper(self, _, line):
        if 'Transaction ID' in line:
            return
            
        parts = line.split(',')
        if len(parts) >= 9:
            try:
                date_str = parts[1].strip()
                gender = parts[3].strip()
                age = int(parts[4])
                category = parts[5].strip()
                total_amount = float(parts[8])
                
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                year_month = date_obj.strftime('%Y-%m')
                age_group = self.get_age_group(age)
                season = self.get_season(date_obj.month)
                
                # üî• –°–û–°–¢–ê–í–ù–´–ï –ö–õ–Æ–ß–ò - –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã
                yield f"TIME_{year_month}", total_amount
                yield f"TIME_SEASON_{season}", total_amount
                
                # –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Ä–µ–∑—ã  
                yield f"DEMO_GENDER_{gender}", total_amount
                yield f"DEMO_AGE_{age_group}", total_amount
                
                # –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–µ —Å—Ä–µ–∑—ã
                yield f"PRODUCT_{category}", total_amount
                
                # üî• –ö–†–û–°–°-–°–ï–ö–¶–ò–û–ù–ù–´–ï –ê–ù–ê–õ–ò–ó–´ (—Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∫–ª—é—á–∏)
                yield f"CROSS_GENDER_CATEGORY_{gender}_{category}", total_amount
                yield f"CROSS_AGE_CATEGORY_{age_group}_{category}", total_amount
                yield f"CROSS_SEASON_CATEGORY_{season}_{category}", total_amount
                yield f"CROSS_GENDER_AGE_{gender}_{age_group}", total_amount
                
                # –¢—Ä–æ–π–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
                yield f"TRIPLE_{gender}_{age_group}_{category}", total_amount
                
            except (ValueError, IndexError) as e:
                self.increment_counter('errors', 'parsing_error', 1)

    def get_age_group(self, age):
        if age <= 24: return "18-24"
        elif age <= 34: return "25-34" 
        elif age <= 44: return "35-44"
        elif age <= 54: return "45-54"
        else: return "55+"

    def get_season(self, month):
        if month in [12, 1, 2]: return "WINTER"
        elif month in [3, 4, 5]: return "SPRING"
        elif month in [6, 7, 8]: return "SUMMER"
        else: return "AUTUMN"

    def reducer(self, key, values):
        total = sum(values)
        count = sum(1 for _ in values)
        
        if key.startswith("TRIPLE"):
            yield key, f"${total:,.2f} ({count} –ø–æ–∫—É–ø–æ–∫)"
        else:
            yield key, f"${total:,.2f}"

if __name__ == '__main__':
    CompositeKeysAnalysis.run()
```

### **3. MULTIPLE OUTPUTS - –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê**

**–°–æ–∑–¥–∞–µ–º `multiple_outputs.py`:**
```python
#!/usr/bin/env python3
from mrjob.job import MRJob
from datetime import datetime
import json

class MultipleOutputsAnalysis(MRJob):

    def mapper(self, _, line):
        if 'Transaction ID' in line:
            return
            
        parts = line.split(',')
        if len(parts) >= 9:
            try:
                date_str = parts[1].strip()
                gender = parts[3].strip()
                age = int(parts[4])
                category = parts[5].strip()
                quantity = int(parts[6])
                price_per_unit = float(parts[7])
                total_amount = float(parts[8])
                
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                year_month = date_obj.strftime('%Y-%m')
                age_group = self.get_age_group(age)
                
                # üî• MULTIPLE OUTPUTS –í –û–î–ù–û–ú MAPPER
                
                # 1. –í–´–•–û–î: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
                yield f"TREND_MONTHLY_{year_month}", total_amount
                yield f"TREND_MONTHLY_COUNT_{year_month}", 1
                
                # 2. –í–´–•–û–î: –î–µ–º–æ–≥—Ä–∞—Ñ–∏—è
                yield f"DEMO_GENDER_{gender}", total_amount
                yield f"DEMO_AGE_{age_group}", total_amount
                
                # 3. –í–´–•–û–î: –ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                yield f"PRODUCT_{category}_REVENUE", total_amount
                yield f"PRODUCT_{category}_QUANTITY", quantity
                yield f"PRODUCT_{category}_AVG_PRICE", price_per_unit
                
                # 4. –í–´–•–û–î: –ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                yield f"METRIC_AVG_RECEIPT", total_amount
                yield f"METRIC_TOTAL_QUANTITY", quantity
                yield f"METRIC_UNIQUE_CATEGORIES", category
                
                # 5. –í–´–•–û–î: –°–µ–≥–º–µ–Ω—Ç—ã –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π
                if total_amount > 200:
                    yield f"SEGMENT_HIGH_VALUE_{gender}_{age_group}", total_amount
                elif total_amount > 100:
                    yield f"SEGMENT_MEDIUM_VALUE_{gender}_{age_group}", total_amount
                else:
                    yield f"SEGMENT_LOW_VALUE_{gender}_{age_group}", total_amount
                    
            except (ValueError, IndexError) as e:
                self.increment_counter('errors', 'parsing_error', 1)

    def get_age_group(self, age):
        if age <= 24: return "18-24"
        elif age <= 34: return "25-34"
        elif age <= 44: return "35-44"
        elif age <= 54: return "45-54"
        else: return "55+"

    def reducer(self, key, values):
        values_list = list(values)
        
        if "COUNT" in key:
            count = sum(values_list)
            yield key, count
        elif "AVG_PRICE" in key or "AVG_RECEIPT" in key:
            avg = sum(values_list) / len(values_list)
            yield key, f"${avg:.2f}"
        elif "UNIQUE" in key:
            unique_count = len(set(values_list))
            yield key, unique_count
        else:
            total = sum(values_list)
            yield key, f"${total:,.2f}"

if __name__ == '__main__':
    MultipleOutputsAnalysis.run()
```

### **4. –¶–ï–ù–û–í–ê–Ø –≠–õ–ê–°–¢–ò–ß–ù–û–°–¢–¨ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è)**

**–°–æ–∑–¥–∞–µ–º `real_price_elasticity.py`:**
```python
#!/usr/bin/env python3
from mrjob.job import MRJob
import statistics

class RealPriceElasticity(MRJob):

    def mapper(self, _, line):
        if 'Transaction ID' in line:
            return
            
        parts = line.split(',')
        if len(parts) >= 9:
            try:
                category = parts[5].strip()
                quantity = int(parts[6])
                price_per_unit = float(parts[7])
                total_amount = float(parts[8])
                
                # –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–æ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è
                price_segment = self.get_price_segment(price_per_unit)
                quantity_segment = self.get_quantity_segment(quantity)
                
                # –≠–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å: –∫–∞–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ–Ω—è–µ—Ç—Å—è —Å —Ü–µ–Ω–æ–π
                yield f"ELASTICITY_{category}_PRICE", price_per_unit
                yield f"ELASTICITY_{category}_QUANTITY", quantity
                yield f"ELASTICITY_{category}_REVENUE", total_amount
                
                # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ü–µ–Ω–æ–≤—ã–º —Å–µ–≥–º–µ–Ω—Ç–∞–º
                yield f"SEGMENT_PRICE_{category}_{price_segment}", total_amount
                yield f"SEGMENT_PRICE_COUNT_{category}_{price_segment}", 1
                
                # –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–æ–≤ –ø–æ–∫—É–ø–æ–∫
                yield f"SEGMENT_QUANTITY_{category}_{quantity_segment}", total_amount
                
                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                if quantity > 0:
                    yield f"PRICE_PER_UNIT_{category}", price_per_unit
                    
            except (ValueError, IndexError) as e:
                self.increment_counter('errors', 'parsing_error', 1)

    def get_price_segment(self, price):
        if price <= 20: return "BUDGET"
        elif price <= 50: return "STANDARD"
        elif price <= 100: return "PREMIUM"
        else: return "LUXURY"

    def get_quantity_segment(self, quantity):
        if quantity == 1: return "SINGLE"
        elif quantity <= 3: return "SMALL"
        elif quantity <= 5: return "MEDIUM"
        else: return "BULK"

    def reducer(self, key, values):
        values_list = list(values)
        
        if "ELASTICITY" in key:
            if "PRICE" in key:
                stats = {
                    'avg': statistics.mean(values_list),
                    'min': min(values_list),
                    'max': max(values_list),
                    'count': len(values_list)
                }
                yield key, stats
            elif "QUANTITY" in key:
                avg_quantity = statistics.mean(values_list)
                yield key, f"{avg_quantity:.1f} –µ–¥."
            else:
                total = sum(values_list)
                yield key, f"${total:,.2f}"
                
        elif "COUNT" in key:
            count = sum(values_list)
            yield key, count
        elif "PRICE_PER_UNIT" in key:
            avg_price = statistics.mean(values_list)
            yield key, f"${avg_price:.2f}"
        else:
            total = sum(values_list)
            yield key, f"${total:,.2f}"

if __name__ == '__main__':
    RealPriceElasticity.run()
```

---

## **üöÄ –ó–ê–ü–£–°–ö –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –°–ö–†–ò–ü–¢–û–í**

```bash
# –ö–æ–ø–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker cp secondary_sort.py namenode:/scripts/
docker cp composite_keys.py namenode:/scripts/ 
docker cp multiple_outputs.py namenode:/scripts/
docker cp real_price_elasticity.py namenode:/scripts/

# –ó–∞–ø—É—Å–∫–∞–µ–º –í–ù–£–¢–†–ò –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
docker-compose exec namenode bash
export PATH="/tmp/python/bin:$PATH"
cd /scripts

# 1. –ó–∞–ø—É—Å–∫–∞–µ–º –í–¢–û–†–ò–ß–ù–£–Æ –°–û–†–¢–ò–†–û–í–ö–£
python3 secondary_sort.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/secondary_sort

# 2. –ó–∞–ø—É—Å–∫–∞–µ–º –°–û–°–¢–ê–í–ù–´–ï –ö–õ–Æ–ß–ò
python3 composite_keys.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/composite_keys

# 3. –ó–∞–ø—É—Å–∫–∞–µ–º MULTIPLE OUTPUTS
python3 multiple_outputs.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/multiple_outputs

# 4. –ó–∞–ø—É—Å–∫–∞–µ–º –¶–ï–ù–û–í–£–Æ –≠–õ–ê–°–¢–ò–ß–ù–û–°–¢–¨
python3 real_price_elasticity.py -r hadoop \
  hdfs://namenode:9000/user/root/input/retail_sales_dataset.csv \
  --output-dir hdfs://namenode:9000/user/root/output/price_elasticity
```

---




